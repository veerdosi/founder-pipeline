{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cacaec-d3cc-4749-a2d5-2d5a732aaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install exa-py openai pandas aiohttp nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fff30f-28f2-4689-ab09-25e85ce9e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from functools import lru_cache\n",
    "import aiohttp\n",
    "import openai\n",
    "from exa_py import Exa\n",
    "import nest_asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Enable nested async in Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307d6f8-025a-460b-bf83-e8dedd734f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "EXA_API_KEY = os.getenv(\"EXA_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY)\n",
    "\n",
    "# Verify keys are set\n",
    "if EXA_API_KEY == \"your_exa_api_key_here\" or OPENAI_API_KEY == \"your_openai_api_key_here\":\n",
    "    print(\"⚠️  WARNING: Please update your API keys in this cell!\")\n",
    "else:\n",
    "    print(\"✅ API keys configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36704057-ae44-41f1-ba70-268cbc46a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIPipeline:\n",
    "    def __init__(self, exa_api_key: str, openai_api_key: str):\n",
    "        self.exa = Exa(exa_api_key)\n",
    "        self.openai_client = openai.OpenAI(api_key=openai_api_key)\n",
    "        self.cache = {}\n",
    "        self.rate_limiter = asyncio.Semaphore(5)\n",
    "        \n",
    "    def deduplicate_companies(self, companies: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Remove duplicate companies\"\"\"\n",
    "        unique = []\n",
    "        seen_names = set()\n",
    "        \n",
    "        for company in companies:\n",
    "            name = company.get(\"name\", \"\").lower().strip()\n",
    "            if name and len(name) > 2 and name not in seen_names:\n",
    "                seen_names.add(name)\n",
    "                unique.append(company)\n",
    "        \n",
    "        return unique\n",
    "    \n",
    "    def extract_name_from_linkedin_url(self, url: str) -> str:\n",
    "        \"\"\"Extract name from LinkedIn URL\"\"\"\n",
    "        try:\n",
    "            parts = url.split('/in/')\n",
    "            if len(parts) > 1:\n",
    "                name_part = parts[1].split('/')[0].replace('-', ' ')\n",
    "                return name_part.title()\n",
    "        except:\n",
    "            pass\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def extract_role_from_title(self, title: str) -> str:\n",
    "        \"\"\"Extract role from LinkedIn title\"\"\"\n",
    "        title_lower = title.lower()\n",
    "        if \"ceo\" in title_lower or \"chief executive\" in title_lower:\n",
    "            return \"CEO\"\n",
    "        elif \"cto\" in title_lower or \"chief technology\" in title_lower:\n",
    "            return \"CTO\"\n",
    "        elif \"founder\" in title_lower:\n",
    "            return \"Founder\"\n",
    "        elif \"president\" in title_lower:\n",
    "            return \"President\"\n",
    "        else:\n",
    "            return \"Executive\"\n",
    "    \n",
    "    def deduplicate_profiles(self, profiles: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Remove duplicate profiles\"\"\"\n",
    "        unique = []\n",
    "        seen_urls = set()\n",
    "        \n",
    "        for profile in profiles:\n",
    "            url = profile.get(\"linkedin_url\", \"\")\n",
    "            if url and url not in seen_urls:\n",
    "                seen_urls.add(url)\n",
    "                unique.append(profile)\n",
    "        \n",
    "        return unique\n",
    "\n",
    "print(\"✅ Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433ebff-992b-41ae-b5d0-599f3eb9ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_ai_companies(pipeline, num_results: int = 50) -> List[Dict]:\n",
    "    \"\"\"Find AI companies using Exa - better than Crunchbase API\"\"\"\n",
    "    \n",
    "    print(\"🔍 Finding AI companies with Exa...\")\n",
    "    \n",
    "    queries = [\n",
    "        \"AI startups Series A funding 2023 2024 artificial intelligence\",\n",
    "        \"machine learning companies venture capital investment TechCrunch\",\n",
    "        \"generative AI startups GPT LLM computer vision funding\",\n",
    "        \"AI unicorn companies billion valuation OpenAI competitor\",\n",
    "        \"artificial intelligence robotics automation startup funding\"\n",
    "    ]\n",
    "    \n",
    "    all_companies = []\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"  Query {i+1}/{len(queries)}: {query[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            result = pipeline.exa.search_and_contents(\n",
    "                query,\n",
    "                type=\"neural\",\n",
    "                use_autoprompt=True,\n",
    "                num_results=num_results // len(queries),\n",
    "                text={\"max_characters\": 2000},\n",
    "                include_domains=[\n",
    "                    \"techcrunch.com\", \"venturebeat.com\", \"crunchbase.com\",\n",
    "                    \"pitchbook.com\", \"bloomberg.com\", \"reuters.com\"\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            for item in result.results:\n",
    "                company = await extract_company_data(pipeline, item.text, item.url, item.title)\n",
    "                if company:\n",
    "                    all_companies.append(company)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Deduplicate and return best companies\n",
    "    unique_companies = pipeline.deduplicate_companies(all_companies)\n",
    "    print(f\"✅ Found {len(unique_companies)} unique AI companies\")\n",
    "    return unique_companies[:num_results]\n",
    "\n",
    "async def extract_company_data(pipeline, content: str, url: str, title: str) -> Optional[Dict]:\n",
    "    \"\"\"Extract structured company data using GPT-4\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Extract company information from this content. Return valid JSON only:\n",
    "    \n",
    "    Content: {content[:1500]}\n",
    "    Title: {title}\n",
    "    \n",
    "    {{\n",
    "        \"name\": \"exact company name\",\n",
    "        \"description\": \"what the company does in 1-2 sentences\",\n",
    "        \"founded_year\": \"YYYY as integer or null\",\n",
    "        \"funding_amount_millions\": \"funding amount in millions USD as number or null\",\n",
    "        \"funding_stage\": \"seed/series-a/series-b/series-c/ipo or null\",\n",
    "        \"founders\": [\"founder names if mentioned\"],\n",
    "        \"location\": \"city, country if mentioned\",\n",
    "        \"ai_focus\": \"specific AI area like NLP, computer vision, robotics, etc\",\n",
    "        \"website\": \"company website if mentioned\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = pipeline.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        result[\"source_url\"] = url\n",
    "        result[\"extraction_date\"] = datetime.now().isoformat()\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"✅ Company finder functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f0d63-180c-4033-aa22-b16dc3bcc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_linkedin_profiles(pipeline, companies: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Find LinkedIn profiles for company founders/executives\"\"\"\n",
    "    \n",
    "    print(\"🔍 Finding LinkedIn profiles...\")\n",
    "    \n",
    "    all_profiles = []\n",
    "    \n",
    "    for i, company in enumerate(companies):\n",
    "        print(f\"  Company {i+1}/{len(companies)}: {company.get('name', 'Unknown')}\")\n",
    "        \n",
    "        profiles = await get_company_profiles(pipeline, company)\n",
    "        for profile in profiles:\n",
    "            profile.update(company)  # Add company data to each profile\n",
    "        all_profiles.extend(profiles)\n",
    "    \n",
    "    print(f\"✅ Found {len(all_profiles)} LinkedIn profiles\")\n",
    "    return all_profiles\n",
    "\n",
    "async def get_company_profiles(pipeline, company: Dict) -> List[Dict]:\n",
    "    \"\"\"Get LinkedIn profiles for a single company\"\"\"\n",
    "    \n",
    "    company_name = company.get(\"name\", \"\")\n",
    "    if not company_name:\n",
    "        return []\n",
    "    \n",
    "    queries = [\n",
    "        f\"{company_name} CEO founder LinkedIn profile\",\n",
    "        f\"{company_name} CTO chief technology officer LinkedIn\",\n",
    "        f'site:linkedin.com/in \"{company_name}\" founder CEO CTO'\n",
    "    ]\n",
    "    \n",
    "    profiles = []\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            result = pipeline.exa.search(\n",
    "                query,\n",
    "                type=\"keyword\",\n",
    "                include_domains=[\"linkedin.com\"],\n",
    "                num_results=5\n",
    "            )\n",
    "            \n",
    "            for item in result.results:\n",
    "                if \"/in/\" in item.url:\n",
    "                    profile = {\n",
    "                        \"person_name\": pipeline.extract_name_from_linkedin_url(item.url),\n",
    "                        \"linkedin_url\": item.url,\n",
    "                        \"title\": item.title,\n",
    "                        \"role\": pipeline.extract_role_from_title(item.title)\n",
    "                    }\n",
    "                    profiles.append(profile)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return pipeline.deduplicate_profiles(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e70b9-a642-42b3-b9bc-cc8b8e3bd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_markets(pipeline, companies: List[Dict]) -> Dict:\n",
    "    \"\"\"Comprehensive market analysis using Exa\"\"\"\n",
    "    \n",
    "    print(\"📊 Analyzing markets...\")\n",
    "    \n",
    "    # Group by AI focus area\n",
    "    sectors = {}\n",
    "    for company in companies:\n",
    "        focus = company.get(\"ai_focus\", \"General AI\")\n",
    "        if focus not in sectors:\n",
    "            sectors[focus] = []\n",
    "        sectors[focus].append(company)\n",
    "    \n",
    "    market_analysis = {}\n",
    "    \n",
    "    for sector, sector_companies in sectors.items():\n",
    "        print(f\"  Analyzing {sector} ({len(sector_companies)} companies)\")\n",
    "        \n",
    "        market_data = await get_sector_metrics(pipeline, sector)\n",
    "        \n",
    "        # Calculate sector stats\n",
    "        funding_amounts = [\n",
    "            float(c.get(\"funding_amount_millions\", 0) or 0) \n",
    "            for c in sector_companies\n",
    "        ]\n",
    "        \n",
    "        market_analysis[sector] = {\n",
    "            **market_data,\n",
    "            \"company_count\": len(sector_companies),\n",
    "            \"avg_funding_millions\": sum(funding_amounts) / len(funding_amounts) if funding_amounts else 0,\n",
    "            \"total_funding_millions\": sum(funding_amounts),\n",
    "            \"top_companies\": [c[\"name\"] for c in sector_companies[:5]],\n",
    "            \"founded_years\": [c.get(\"founded_year\") for c in sector_companies if c.get(\"founded_year\")]\n",
    "        }\n",
    "    \n",
    "    print(f\"✅ Analyzed {len(market_analysis)} sectors\")\n",
    "    return market_analysis\n",
    "\n",
    "async def get_sector_metrics(pipeline, sector: str) -> Dict:\n",
    "    \"\"\"Get market metrics for a specific sector\"\"\"\n",
    "    \n",
    "    queries = [\n",
    "        f\"{sector} market size 2024 billion revenue industry report\",\n",
    "        f\"{sector} growth rate CAGR forecast venture capital investment\",\n",
    "        f\"{sector} competitive landscape market leaders analysis\"\n",
    "    ]\n",
    "    \n",
    "    all_content = []\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            result = pipeline.exa.search_and_contents(\n",
    "                query,\n",
    "                type=\"neural\",\n",
    "                use_autoprompt=True,\n",
    "                num_results=3,\n",
    "                text={\"max_characters\": 2000},\n",
    "                include_domains=[\n",
    "                    \"mckinsey.com\", \"bcg.com\", \"statista.com\", \n",
    "                    \"grandviewresearch.com\", \"marketsandmarkets.com\"\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            for item in result.results:\n",
    "                all_content.append(item.text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Extract metrics using GPT-4\n",
    "    return await extract_market_metrics(pipeline, all_content, sector)\n",
    "\n",
    "async def extract_market_metrics(pipeline, content_list: List[str], sector: str) -> Dict:\n",
    "    \"\"\"Extract market metrics from research content\"\"\"\n",
    "    \n",
    "    combined_content = \"\\n\".join(content_list[:3])  # Use top 3 sources\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Extract market metrics for {sector} from this research content. Return valid JSON only:\n",
    "    \n",
    "    {combined_content[:3000]}\n",
    "    \n",
    "    {{\n",
    "        \"market_size_billion\": \"market size in billions USD as number or null\",\n",
    "        \"cagr_percent\": \"growth rate percentage as number or null\",\n",
    "        \"market_stage\": \"emerging/growth/mature\",\n",
    "        \"key_trends\": [\"trend1\", \"trend2\", \"trend3\"],\n",
    "        \"geographic_focus\": [\"North America\", \"Europe\", \"Asia\"],\n",
    "        \"confidence_score\": \"data quality score 1-10 as number\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = pipeline.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"market_size_billion\": None,\n",
    "            \"cagr_percent\": None,\n",
    "            \"market_stage\": \"unknown\",\n",
    "            \"key_trends\": [],\n",
    "            \"geographic_focus\": [],\n",
    "            \"confidence_score\": 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da4d72-1702-46e8-b625-875657f4e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_complete_pipeline(pipeline, num_companies: int = 50) -> tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"Run the complete enhanced pipeline\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting Enhanced AI Company Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Find AI companies\n",
    "        companies = await find_ai_companies(pipeline, num_companies)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        with open(\"checkpoint_companies.json\", \"w\") as f:\n",
    "            json.dump(companies, f, indent=2)\n",
    "        print(f\"💾 Saved companies checkpoint\")\n",
    "        \n",
    "        # Step 2: Find LinkedIn profiles\n",
    "        profiles = await find_linkedin_profiles(pipeline, companies)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        with open(\"checkpoint_profiles.json\", \"w\") as f:\n",
    "            json.dump(profiles, f, indent=2)\n",
    "        print(f\"💾 Saved profiles checkpoint\")\n",
    "        \n",
    "        # Step 3: Market analysis\n",
    "        market_analysis = await analyze_markets(pipeline, companies)\n",
    "        \n",
    "        # Step 4: Combine everything\n",
    "        final_dataset = []\n",
    "        for profile in profiles:\n",
    "            sector = profile.get(\"ai_focus\", \"General AI\")\n",
    "            profile[\"market_data\"] = market_analysis.get(sector, {})\n",
    "            final_dataset.append(profile)\n",
    "        \n",
    "        # Save results\n",
    "        df = pd.DataFrame(final_dataset)\n",
    "        df.to_csv(\"enhanced_ai_companies.csv\", index=False)\n",
    "        \n",
    "        with open(\"market_analysis.json\", \"w\") as f:\n",
    "            json.dump(market_analysis, f, indent=2)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        print(\"\\n🎉 Pipeline Complete!\")\n",
    "        print(f\"⏱️  Execution time: {execution_time:.1f} seconds\")\n",
    "        print(f\"🏢 Companies found: {len(companies)}\")\n",
    "        print(f\"👤 Profiles found: {len(profiles)}\")\n",
    "        print(f\"📊 Sectors analyzed: {len(market_analysis)}\")\n",
    "        print(f\"💾 Data saved to: enhanced_ai_companies.csv\")\n",
    "        \n",
    "        return df, market_analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pipeline error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206e149-538b-43f7-bb24-082f2e9d44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = AIPipeline(EXA_API_KEY, OPENAI_API_KEY)\n",
    "\n",
    "# Run complete pipeline (adjust num_companies as needed)\n",
    "df, market_data = await run_complete_pipeline(pipeline, num_companies=30)\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n📋 Sample Results:\")\n",
    "    display_cols = ['name', 'person_name', 'role', 'ai_focus', 'funding_amount_millions']\n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    print(df[available_cols].head())\n",
    "else:\n",
    "    print(\"❌ Pipeline failed to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ed3ec-6f08-462d-84cb-18fab3c0862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if market_data:\n",
    "    print(\"📊 MARKET ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for sector, data in market_data.items():\n",
    "        print(f\"\\n🎯 {sector.upper()}\")\n",
    "        print(f\"   Companies: {data.get('company_count', 0)}\")\n",
    "        print(f\"   Market Size: ${data.get('market_size_billion', 'N/A')}B\")\n",
    "        print(f\"   Growth Rate: {data.get('cagr_percent', 'N/A')}%\")\n",
    "        print(f\"   Stage: {data.get('market_stage', 'Unknown')}\")\n",
    "        print(f\"   Total Funding: ${data.get('total_funding_millions', 0):.1f}M\")\n",
    "        print(f\"   Avg Funding: ${data.get('avg_funding_millions', 0):.1f}M\")\n",
    "        \n",
    "        if data.get('key_trends'):\n",
    "            print(f\"   Key Trends: {', '.join(data['key_trends'][:3])}\")\n",
    "        \n",
    "        if data.get('top_companies'):\n",
    "            print(f\"   Top Companies: {', '.join(data['top_companies'][:3])}\")\n",
    "    \n",
    "    # Overall stats\n",
    "    total_companies = sum(data.get('company_count', 0) for data in market_data.values())\n",
    "    total_market_size = sum(data.get('market_size_billion', 0) or 0 for data in market_data.values())\n",
    "    total_funding = sum(data.get('total_funding_millions', 0) for data in market_data.values())\n",
    "    \n",
    "    print(f\"\\n🌟 OVERALL SUMMARY\")\n",
    "    print(f\"   Total Companies: {total_companies}\")\n",
    "    print(f\"   Combined Market Size: ${total_market_size:.1f}B\")\n",
    "    print(f\"   Total Funding Tracked: ${total_funding:.1f}M\")\n",
    "    print(f\"   Sectors Analyzed: {len(market_data)}\")\n",
    "else:\n",
    "    print(\"❌ No market data available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
